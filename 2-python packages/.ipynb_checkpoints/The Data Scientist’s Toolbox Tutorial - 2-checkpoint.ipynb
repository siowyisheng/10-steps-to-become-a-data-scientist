{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1247188a5193a0bb99f176fea36dc594d283160e"
   },
   "source": [
    "# <div style=\"text-align: center\">The Data Scientist’s Toolbox Tutorial - 2</div>\n",
    "\n",
    "### <div style=\"text-align: center\">Quite Practical and Far from any Theoretical Concepts</div>\n",
    "<img src='https://chengotto.com/wp-content/uploads/2018/02/images.duckduckgo2-600x338.jpg'>\n",
    "<div style=\"text-align:center\">last update: <b>30/12/2018</b></div>\n",
    "\n",
    "\n",
    ">###### You may  be interested have a look at the previous version: [**The Data Scientist’s Toolbox Tutorial - 1**](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1)\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "You can Fork and Run this kernel on Github:\n",
    "> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    " **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated**\n",
    " \n",
    " -----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a45d14ee727bf2f88a7cd0ba5e6aa338977d10b"
   },
   "source": [
    " <a id=\"top\"></a> <br>\n",
    "## Notebook  Content\n",
    "1. [Introduction](#1)\n",
    "    1. [Import](#2)\n",
    "    1. [Version](#3)\n",
    "1. [Sklearn](#4)\n",
    "    1. [Data Collection](#5)\n",
    "    1. [Framework](#6)\n",
    "    1. [Applications](#7)\n",
    "    1. [How to use Sklearn Data Set? ](#8)\n",
    "    1. [Loading external data](#9)\n",
    "    1. [Model Deployment](#10)\n",
    "    1. [Families of ML algorithms](#11)\n",
    "    1. [Prepare Features & Targets](#12)\n",
    "    1. [Accuracy and precision](#13)\n",
    "    1. [Estimators](#14)\n",
    "    1. [Predictors](#15)\n",
    "    1. [K-Nearest Neighbours](#16)\n",
    "    1. [Radius Neighbors Classifier](#17)\n",
    "    1. [Logistic Regression](#18)\n",
    "    1. [Passive Aggressive Classifier](#19)\n",
    "    1. [Naive Bayes](#20)\n",
    "    1. [BernoulliNB](#21)\n",
    "    1. [SVM](#22)\n",
    "    1. [Nu-Support Vector Classification](#23)\n",
    "    1. [Linear Support Vector Classification](#24)\n",
    "    1. [Decision Tree](#25)\n",
    "    1. [ExtraTreeClassifier](#26)\n",
    "    1. [Neural network](#27)\n",
    "        1. [What is a Perceptron?](#28)\n",
    "        1. [The XOR Problem](#29)\n",
    "    1. [RandomForest](#30)\n",
    "    1. [Bagging classifier ](#31)\n",
    "    1. [AdaBoost classifier](#32)\n",
    "    1. [Gradient Boosting Classifier](#33)\n",
    "    1. [Linear Discriminant Analysis](#34)\n",
    "    1. [Quadratic Discriminant Analysis](#35)\n",
    "    1. [Kmeans](#36)\n",
    "        1. [Plot classification probability](#37)\n",
    "1. [conclusion](#47)\n",
    "1. [References](#48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec7344e7f2a1bafa9a44a518722fcd8ec47c374b"
   },
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "# 1-Introduction\n",
    "This Kernel is mostly for **beginners**, and of course, all **professionals** who think they need to review  their  knowledge.\n",
    "Also, this is  the second version for (  [The Data Scientist’s Toolbox Tutorial - 1](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1) ) and we will continue with other important packages in this kernel.keep following!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e28cde75726e3617dc80585626f7f8a1297a9e4"
   },
   "source": [
    "<a id=\"11\"></a> <br>\n",
    "##   1-1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import get_dummies\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "import sklearn\n",
    "import scipy\n",
    "import numpy\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c3c434ac82d771c5549c4f36d0e8e878489f252"
   },
   "source": [
    "<a id=\"12\"></a> <br>\n",
    "## 1-2 Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "72fdff866b7cbe404867e82f9122e16fc33facf2"
   },
   "outputs": [],
   "source": [
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "print('seaborn: {}'.format(sns.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('Python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4284a92f8326eb09dccf0a795f44931c5a7487cc"
   },
   "source": [
    "<a id=\"13\"></a> <br>\n",
    "## 1-3 Setup\n",
    "\n",
    "A few tiny adjustments for better **code readability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bfb701e45e93aea0b3ed64e148ca2fdb53559038",
    "collapsed": true
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "# 2- Numerical Python (NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "db9a850ebb440ca960a0713d822e20090bc10601"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79699175b4559f509181d359393167f801735485"
   },
   "source": [
    "<a id=\"21\"></a> <br>\n",
    "## 2-1 NumPy :Creating Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb5123cfa4687a819758ea82810984fa69d631e3"
   },
   "source": [
    "Create a list and convert it to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1cdc9404b31261269891723ddc59064802063041"
   },
   "outputs": [],
   "source": [
    "mylist = [1, 2, 3]\n",
    "x = np.array(mylist)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85123a6bf0589918ff03fe9916b06635fa32b776"
   },
   "source": [
    "<br>\n",
    "Or just pass in a list directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "dca7dd9319716e863760bb7c4e1e47a1c17d7b1b"
   },
   "outputs": [],
   "source": [
    "y = np.array([4, 5, 6])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a29d1e6bb19131b3bde9ae197b562cf5c905f2a"
   },
   "source": [
    "<br>\n",
    "Pass in a list of lists to create a multidimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e18e77b6d1becf1b7ded3a4daa361dbe3f985d96"
   },
   "outputs": [],
   "source": [
    "m = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "956c870e985074aadd2aa97b8a4c820c64bd7d2b"
   },
   "source": [
    "<br>\n",
    "Use the shape method to find the dimensions of the array. (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7e5472233313b1eb806b7e9dfd2478f4155b23d0"
   },
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d20433435f865bf4593ee8b5eae4cb2173794a57"
   },
   "source": [
    "<br>\n",
    "`arange` returns evenly spaced values within a given interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "87aded8cbe232bfcb4ce246ecf1bac0b70d9477e"
   },
   "outputs": [],
   "source": [
    "n = np.arange(0, 30, 2) # start at 0 count up by 2, stop before 30\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef6d0651972cb576188cd986830aae2d53bb20b8"
   },
   "source": [
    "<br>\n",
    "`reshape` returns an array with the same data with a new shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6722026f830d545bfd21a2760f80c20e33c0d757"
   },
   "outputs": [],
   "source": [
    "n = n.reshape(3, 5) # reshape array to be 3x5\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a47a0e9b094d81ae9ec235cd33d395ca34c379b3"
   },
   "source": [
    "<br>\n",
    "`linspace` returns evenly spaced numbers over a specified interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "099d0b4b7f3c6e5aef6cebd760e3c6b8111205d8"
   },
   "outputs": [],
   "source": [
    "o = np.linspace(0, 4, 9) # return 9 evenly spaced values from 0 to 4\n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5abb93fd66c344624ad2bb5e91ec1cd8a9ab220"
   },
   "source": [
    "<br>\n",
    "`resize` changes the shape and size of array in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "66de4ad6fbb8a2ffe7251b667de732fe0048c39c"
   },
   "outputs": [],
   "source": [
    "o.resize(3, 3)\n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95af33fa252b8ccc4afad8666e0a7ced2d83aee9"
   },
   "source": [
    "<br>\n",
    "`ones` returns a new array of given shape and type, filled with ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "015e5a604fceb5b335760d85f090812416ab0edd"
   },
   "outputs": [],
   "source": [
    "np.ones((3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "415ba7eb6ffcca82d1ad73b6e652d77c2b40c4c7"
   },
   "source": [
    "<br>\n",
    "`zeros` returns a new array of given shape and type, filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4833b4502eac60ec53ca4ab55f10653103be3584"
   },
   "outputs": [],
   "source": [
    "np.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "acbef4f6ab93b0ea5ed8bea30ec0eddbce8415f1"
   },
   "source": [
    "<br>\n",
    "`eye` returns a 2-D array with ones on the diagonal and zeros elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5e4e8112e5829b290385bd076041d9d0c43bdd4e"
   },
   "outputs": [],
   "source": [
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb258a18b84c56c26c19e5e467f8886a3209eb6d"
   },
   "source": [
    "<br>\n",
    "`diag` extracts a diagonal or constructs a diagonal array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0167bbb06dc5175a14e2d1844b3e92c3f601e156"
   },
   "outputs": [],
   "source": [
    "np.diag(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05f0ea0d69c70181a0ddee0b0a0670afc1a5761c"
   },
   "source": [
    "<br>\n",
    "Create an array using repeating list (or see `np.tile`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "76f7c4dd56d1f9ba9c8dcc3bf3b0e67bc62326de"
   },
   "outputs": [],
   "source": [
    "np.array([1, 2, 3] * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9d6935951d0df2a4d60f66b302da7b876006c71"
   },
   "source": [
    "<br>\n",
    "Repeat elements of an array using `repeat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7299b4990895d4ea8a59447489fa6fbc0cde5ea6"
   },
   "outputs": [],
   "source": [
    "np.repeat([1, 2, 3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01250c2ea726f387db5f3fab5a004e741e574a35"
   },
   "source": [
    "<a id=\"22\"></a> <br>\n",
    "## 2-2 Numpy:Combining Arrays\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0dc57919256360d1ac309813fb6e836f75d17484"
   },
   "outputs": [],
   "source": [
    "p = np.ones([2, 3], int)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98aa86e98478bcad2ce35eded8e2adb825bbf709"
   },
   "source": [
    "<br>\n",
    "Use `vstack` to stack arrays in sequence vertically (row wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "48b0f8194df6a4f63932d97b24883d6a5d69d0df"
   },
   "outputs": [],
   "source": [
    "np.vstack([p, 2*p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a2cf2eb6fdf3deccca31df9979dd978241adadb8"
   },
   "source": [
    "<br>\n",
    "Use `hstack` to stack arrays in sequence horizontally (column wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "834984b63056d7161f261d868d85b83f24403287"
   },
   "outputs": [],
   "source": [
    "np.hstack([p, 2*p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b82f24eec48ab5206a47d04a36e5e639dad7f9a1"
   },
   "source": [
    "<a id=\"23\"></a> <br>\n",
    "## 2-3 Numpy:Operations\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d58a4bb35b9f1525736b28ffc7e2b6ead4035266"
   },
   "source": [
    "Use `+`, `-`, `*`, `/` and `**` to perform element wise addition, subtraction, multiplication, division and power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ba8b42fcdcdc83e6f43df83b73665aa289e9786"
   },
   "outputs": [],
   "source": [
    "print(x + y) # elementwise addition     [1 2 3] + [4 5 6] = [5  7  9]\n",
    "print(x - y) # elementwise subtraction  [1 2 3] - [4 5 6] = [-3 -3 -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd42ade6bd206750b5dde1086b06bde519f2b1df"
   },
   "outputs": [],
   "source": [
    "print(x * y) # elementwise multiplication  [1 2 3] * [4 5 6] = [4  10  18]\n",
    "print(x / y) # elementwise divison         [1 2 3] / [4 5 6] = [0.25  0.4  0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3370d5b9b8ca04ed5be48331c3d6d4d08738ab5d"
   },
   "outputs": [],
   "source": [
    "print(x**2) # elementwise power  [1 2 3] ^2 =  [1 4 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e665d9db501694e29f54b02de56befaf69305629"
   },
   "source": [
    "<br>\n",
    "**Dot Product:**  \n",
    "\n",
    "$ \\begin{bmatrix}x_1 \\ x_2 \\ x_3\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}y_1 \\\\ y_2 \\\\ y_3\\end{bmatrix}\n",
    "= x_1 y_1 + x_2 y_2 + x_3 y_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b45a94567cf5801e05869bde614e831603b1599a"
   },
   "outputs": [],
   "source": [
    "x.dot(y) # dot product  1*4 + 2*5 + 3*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b27ce9c3b1328461ba14f5efdd36079e3f827951"
   },
   "outputs": [],
   "source": [
    "z = np.array([y, y**2])\n",
    "print(len(z)) # number of rows of array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "30ab350aa70687cbdd087d86386b96504aec4479"
   },
   "source": [
    "<br>\n",
    "Let's look at transposing arrays. Transposing permutes the dimensions of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2630bf81db6d00483f7e0abd3a3c3af28144d55f"
   },
   "outputs": [],
   "source": [
    "z = np.array([y, y**2])\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bb90454186cab0c688be9a01ff84c7ca67fa6a9"
   },
   "source": [
    "<br>\n",
    "The shape of array `z` is `(2,3)` before transposing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdcbfc2e1c9b985a83aefa1a5972aa919acb8365"
   },
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b796b3d6c4e9a90e4fb5332d708398bb848c2e4"
   },
   "source": [
    "<br>\n",
    "Use `.T` to get the transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ca46bf46ed15a5fa3af7e2d325ac68bc8785f05"
   },
   "outputs": [],
   "source": [
    "z.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2949665fb40cdb932376219b6d78156265d5ebf"
   },
   "source": [
    "<br>\n",
    "The number of rows has swapped with the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e48e8eff60259a9c865cf2dae88a3ce1641e826c"
   },
   "outputs": [],
   "source": [
    "z.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08fac1d78a66fdd513372cd31eaa5f973655e80a"
   },
   "source": [
    "<br>\n",
    "Use `.dtype` to see the data type of the elements in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e1ea214c877f23d670b72f06060c2dee1bdaee5"
   },
   "outputs": [],
   "source": [
    "z.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70da3bcabbc0631bb11b48796106c07f4de41ba8"
   },
   "source": [
    "<br>\n",
    "Use `.astype` to cast to a specific type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60684ed5f18c88c4ef4e2fe4207fa94eede9d993"
   },
   "outputs": [],
   "source": [
    "z = z.astype('f')\n",
    "z.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1199442dd07a4a4eef965c584d9e0f443c40013"
   },
   "source": [
    "<a id=\"24\"></a> <br>\n",
    "## 2-4 Numpy: Math Functions\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01121300b7b5b8a83d213d4f065383da19d5f7d8"
   },
   "source": [
    "Numpy has many built in math functions that can be performed on arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1eaeb06cf68d055f6a5536ea72a17606b6762c1"
   },
   "outputs": [],
   "source": [
    "a = np.array([-4, -2, 1, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2918e83be55935fa03fd24924bc7f07a271c40d3"
   },
   "outputs": [],
   "source": [
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e86a6ea98c6c86dbe7a96612af4f37452b23670"
   },
   "outputs": [],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e8e48425f65e90a18a29fb7983dc6aa424f8445"
   },
   "outputs": [],
   "source": [
    "a.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27131855b2c26a5f90c6524d4a8c7ed0266bf378"
   },
   "outputs": [],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a020531df7f87af15577e986699e80f892300773"
   },
   "outputs": [],
   "source": [
    "a.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d26c78ddd00e9387ba4214470debcc8147fd2bc"
   },
   "source": [
    "<br>\n",
    "`argmax` and `argmin` return the index of the maximum and minimum values in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd6f6aee91fc8dd99cc5a8359dc81ce1d443e77f"
   },
   "outputs": [],
   "source": [
    "a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59aeec1ba92a0eb4c6928564e64445e6ce46cc3c"
   },
   "outputs": [],
   "source": [
    "a.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf3ad4800506fd903882f60d811ca2548756e7c8"
   },
   "source": [
    "<a id=\"25\"></a> <br>\n",
    "\n",
    "## 2-5 Numpy:Indexing / Slicing\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82ca4b616a46de3280b5a50df4c0114298d07aea"
   },
   "outputs": [],
   "source": [
    "s = np.arange(13)**2\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "417c1b56b9d3eca21021422bde199036c3f08ec3"
   },
   "source": [
    "<br>\n",
    "Use bracket notation to get the value at a specific index. Remember that indexing starts at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f90f5dee19a73afde4e9455b47c0dbe86c9ce6b"
   },
   "outputs": [],
   "source": [
    "s[0], s[4], s[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d0cf8a30f9b1bd1f8dc60a46d3271e5cac235d0"
   },
   "source": [
    "<br>\n",
    "Use `:` to indicate a range. `array[start:stop]`\n",
    "\n",
    "\n",
    "Leaving `start` or `stop` empty will default to the beginning/end of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ea11cc5be369a751b250e7085cf507b122bcf88"
   },
   "outputs": [],
   "source": [
    "s[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd42e9a4274baebf747c627767a273ef8ca9a26f"
   },
   "source": [
    "<br>\n",
    "Use negatives to count from the back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce51a60f59516b22174f97a4f7c6da6c75322a8b"
   },
   "outputs": [],
   "source": [
    "s[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fdd94c22e7ceb4cac00001bd98f09d5d879613e"
   },
   "source": [
    "<br>\n",
    "A second `:` can be used to indicate step-size. `array[start:stop:stepsize]`\n",
    "\n",
    "Here we are starting 5th element from the end, and counting backwards by 2 until the beginning of the array is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f28245bea6ab9a1bed7a76859ddfbb295ea95038"
   },
   "outputs": [],
   "source": [
    "s[-5::-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f2295df96d9e7da01cde82bf87d5c7157bd9d21"
   },
   "source": [
    "<br>\n",
    "Let's look at a multidimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "582e15f695a2891826ef4eb8e913a0dc61913898"
   },
   "outputs": [],
   "source": [
    "r = np.arange(36)\n",
    "r.resize((6, 6))\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26fd89ebfe4b92cedad89152753918608b68eafe"
   },
   "source": [
    "<br>\n",
    "Use bracket notation to slice: `array[row, column]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bf0f1e77c5243c3e2b846f7b268c4891786621b"
   },
   "outputs": [],
   "source": [
    "r[2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fcbf322288c6671ef799299b5ddb828b68b8cab9"
   },
   "source": [
    "<br>\n",
    "And use : to select a range of rows or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64d430ac4626977723c6357865a5297699e5323d"
   },
   "outputs": [],
   "source": [
    "r[3, 3:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e109144f7316b357450c4b3cae3cb61ad327f5d9"
   },
   "source": [
    "<br>\n",
    "Here we are selecting all the rows up to (and not including) row 2, and all the columns up to (and not including) the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b80dc3ba5c970afe2db37c23599d476399b1c68"
   },
   "outputs": [],
   "source": [
    "r[:2, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c5126aa54a1e6b9d0d078f2226b68d3fb42c4a2"
   },
   "source": [
    "<br>\n",
    "This is a slice of the last row, and only every other element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "054f80d47b0e2d249a9140321846ff7b50daba1f"
   },
   "outputs": [],
   "source": [
    "r[-1, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62e5354b353e1fe2e60036f2c3f94909a8af1b7b"
   },
   "source": [
    "<br>\n",
    "We can also perform conditional indexing. Here we are selecting values from the array that are greater than 30. (Also see `np.where`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5476c43a5e7d195804cac7517abbdbcdbc234829"
   },
   "outputs": [],
   "source": [
    "r[r > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77ae22731783157aaecdd019be77004504b943af"
   },
   "source": [
    "<br>\n",
    "Here we are assigning all values in the array that are greater than 30 to the value of 30.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6651ea99641526b7df83e7a9d9c1efe4eab9dc99"
   },
   "outputs": [],
   "source": [
    "r[r > 30] = 30\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6189d2e7dc9038dc1c4f2ed95a47fad76d700890"
   },
   "source": [
    "<a id=\"26\"></a> <br>\n",
    "## 2-6 Numpy :Copying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad2453d83a8db6de311e9265672e9b10b0337284"
   },
   "source": [
    "Be careful with copying and modifying arrays in NumPy!\n",
    "\n",
    "\n",
    "`r2` is a slice of `r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6bb5dab7586dd4cfbc93b2cee05c57aae1e8518"
   },
   "outputs": [],
   "source": [
    "r2 = r[:3,:3]\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "65d42e0a4cade74ae9b2b587f182efaa8a4b1dbf"
   },
   "source": [
    "<br>\n",
    "Set this slice's values to zero ([:] selects the entire array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9026a103a457054124258eefca3492008f884ef4"
   },
   "outputs": [],
   "source": [
    "r2[:] = 0\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f73d4004c9181b5cffddf6f13b452d7e40cea3f9"
   },
   "source": [
    "<br>\n",
    "`r` has also been changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80c0d26d5cb0374f82929e3d79c183f5e116f4ea"
   },
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8a21fd94e5dfcd322ec0017e89302533ac3cf2d"
   },
   "source": [
    "<br>\n",
    "To avoid this, use `r.copy` to create a copy that will not affect the original array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2b2e17295f75a5a3b8dacf5ca65b4c4f3b6ca47"
   },
   "outputs": [],
   "source": [
    "r_copy = r.copy()\n",
    "r_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2ef3568f7ac932cc45931854410cbb9e4d909df8"
   },
   "source": [
    "<br>\n",
    "Now when r_copy is modified, r will not be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f7fa9e1b65eea1e9514fbd6f91a2720822430ba"
   },
   "outputs": [],
   "source": [
    "r_copy[:] = 10\n",
    "print(r_copy, '\\n')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "752b09b0f8f1606d55bf0423d3f2d9cb162d3ce9"
   },
   "source": [
    "<a id=\"27\"></a> <br>\n",
    "## 2-7 Numpy: Iterating Over Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a7f8c639e5f8cbdbd0cf2fe4c78504955ec2ccb"
   },
   "source": [
    "Let's create a new 4 by 3 array of random numbers 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c1496dab8d8f90434e8c44e63c225bfb3ca9713f"
   },
   "outputs": [],
   "source": [
    "test = np.random.randint(0, 10, (4,3))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf971c58819a069592b3d5c195cf9e21faa4797b"
   },
   "source": [
    "<br>\n",
    "Iterate by row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "993bb7b7f1be5a0b088caac550c32257dd1c9297"
   },
   "outputs": [],
   "source": [
    "for row in test:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5b7fa4289acc25093efbbc99fe36355073bcd02"
   },
   "source": [
    "<br>\n",
    "Iterate by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9de357edca10cf7708e1c5b37ef5a0ad337fcbbf"
   },
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    print(test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00ed3013376dff60b43f6f1eb5091580279063ad"
   },
   "source": [
    "<br>\n",
    "Iterate by row and index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a75a7881baf87a49a3f48236fc9a9281f2ace310"
   },
   "outputs": [],
   "source": [
    "for i, row in enumerate(test):\n",
    "    print('row', i, 'is', row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08f51011e8d4da3ab72a33ccb6daca3c97832eb4"
   },
   "source": [
    "<br>\n",
    "Use `zip` to iterate over multiple iterables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63709cf63fc6e5596bc540055a287d56a57c55df"
   },
   "outputs": [],
   "source": [
    "test2 = test**2\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88776121d1063744cdb0d1df15320af35a40690f"
   },
   "outputs": [],
   "source": [
    "for i, j in zip(test, test2):\n",
    "    print(i,'+',j,'=',i+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2ec9941ed71b0d102881252688723804c536b65"
   },
   "source": [
    "<a id=\"28\"></a> <br>\n",
    "## 2-8  Numpy: The Series Data Structure\n",
    "One-dimensional ndarray with axis labels (including time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff60c47c0ee85b3534fa0eeb1fc6c18951e13a93"
   },
   "outputs": [],
   "source": [
    "animals = ['Tiger', 'Bear', 'Moose']\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b9d3593c2f04eb52439d1e2f6eaced42103b385"
   },
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac6b145a659c5c6e143e47a726be2d2bc904ea05"
   },
   "outputs": [],
   "source": [
    "animals = ['Tiger', 'Bear', None]\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "608363b045521c88d96135d4651624753a0a97f8"
   },
   "outputs": [],
   "source": [
    "numbers = [1, 2, None]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81c84dd1739a442c3eca83911b9e9cd146beccf1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.nan == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee829b3241dc2b99e7aeb8b16daa61f43516a08e"
   },
   "outputs": [],
   "source": [
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c39a1b7d020fa502a055e4befa580529da3d9206"
   },
   "outputs": [],
   "source": [
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "703803f890a0c351d5122b4f509c0835b949481d"
   },
   "outputs": [],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a4a03374c688db5bc1cb49cf0ae67a166f33ab5"
   },
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16a45c1d82eb06da0e940aa9304455d5b6629723"
   },
   "outputs": [],
   "source": [
    "s = pd.Series(['Tiger', 'Bear', 'Moose'], index=['India', 'America', 'Canada'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5c017e5124d3c8c62bbe91b16ae5e2fb76f2cd5"
   },
   "outputs": [],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports, index=['Golf', 'Sumo', 'Hockey'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91a03b68b0698ad0f0736d0a8106bb4c2023437d"
   },
   "source": [
    "<a id=\"29\"></a> <br>\n",
    "# 2-9 Numpy: Querying a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c44f80eadf6e60f8d1d966594169e6e579fd91a"
   },
   "outputs": [],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "560e0377aa2d53cc14f61a42a6492f99932a6eab"
   },
   "outputs": [],
   "source": [
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c0e34116ab3b36363b7d7ffde48d3520b493d50"
   },
   "outputs": [],
   "source": [
    "s.loc['Golf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12dce7548346ce489c21f50e02a30e4a7dad6a81"
   },
   "outputs": [],
   "source": [
    "s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a44e0fd0b5ea294bfde2383f3ed660bb4dc7c032"
   },
   "outputs": [],
   "source": [
    "s['Golf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97f106d843bd9da560c4aaa36e9a2baf0fd5f820"
   },
   "outputs": [],
   "source": [
    "sports = {99: 'Bhutan',\n",
    "          100: 'Scotland',\n",
    "          101: 'Japan',\n",
    "          102: 'South Korea'}\n",
    "s = pd.Series(sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c8d10a115a42956c1bf95a925006f1a8f44ac77"
   },
   "outputs": [],
   "source": [
    "s = pd.Series([100.00, 120.00, 101.00, 3.00])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a877d83b4ea29606ab220884b742b9436640a87b"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for item in s:\n",
    "    total+=item\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb4aaac9d42d6ad0df5b0d766bf142cec13ca640"
   },
   "outputs": [],
   "source": [
    "total = np.sum(s)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5ec441b291558581a79c6bda7d67ee7df640ac4"
   },
   "outputs": [],
   "source": [
    "#this creates a big series of random numbers\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cafe2341bfb1b9419fcff2624e9973a12beb579a"
   },
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0028ee6c78f4715a1848458c3b5ef2ea75e601b"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "summary = 0\n",
    "for item in s:\n",
    "    summary+=item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbc4da9b2ba74a04d797ff837bddf7553b4625d9"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "summary = np.sum(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9ef0f8d0db28ffb3f5c92c86dbcffd8b9d01840"
   },
   "outputs": [],
   "source": [
    "s+=2 #adds two to each item in s using broadcasting\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f092ba84abb6a9172a23030b25caa23b7dea1c3f"
   },
   "outputs": [],
   "source": [
    "for label, value in s.iteritems():\n",
    "    s.set_value(label, value+2)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "979c2ea48abace1804d37a316ecf8a7cb0b53aa2"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(0,1000,100))\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label]= value+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "84c6c0358bf55fd26254ae784ae2b60b3d7c3526"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(0,1000,100))\n",
    "s+=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35dabb561b6b3aaf6520311c68004880cadf5f7d"
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s.loc['Animal'] = 'Bears'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f40d7bded3fd8cea73b8ab31e945929d75a57f4"
   },
   "outputs": [],
   "source": [
    "original_sports = pd.Series({'Archery': 'Bhutan',\n",
    "                             'Golf': 'Scotland',\n",
    "                             'Sumo': 'Japan',\n",
    "                             'Taekwondo': 'South Korea'})\n",
    "cricket_loving_countries = pd.Series(['Australia',\n",
    "                                      'Barbados',\n",
    "                                      'Pakistan',\n",
    "                                      'England'], \n",
    "                                   index=['Cricket',\n",
    "                                          'Cricket',\n",
    "                                          'Cricket',\n",
    "                                          'Cricket'])\n",
    "all_countries = original_sports.append(cricket_loving_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95fa6b69a0927865a896c7a518ba848c3b994cad"
   },
   "outputs": [],
   "source": [
    "original_sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb617195f684747e2a79b87eb7307e832f2bfe50"
   },
   "outputs": [],
   "source": [
    "cricket_loving_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5274031be8720d734db1866f20ad048c4c2ea7da"
   },
   "outputs": [],
   "source": [
    "all_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33c9d9f54962decaa00a7328b124252ddcf2b661"
   },
   "outputs": [],
   "source": [
    "all_countries.loc['Cricket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f7c5d5041dc630abeaff47ff5a96a0dd53db8e5"
   },
   "source": [
    "<a id=\"210\"></a> <br>\n",
    "## 2-10 Distributions in Numpy\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "96be284ba6d63fd0b1db5641a21d75aacdfb7da4"
   },
   "outputs": [],
   "source": [
    "np.random.binomial(1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4ae2c7ff2cf941bae62be23864a1685a196551d0"
   },
   "outputs": [],
   "source": [
    "np.random.binomial(1000, 0.5)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c5e89f6f0c7376c164f80dc4c5d582b0a639e254"
   },
   "outputs": [],
   "source": [
    "chance_of_tornado = 0.01/100\n",
    "np.random.binomial(100000, chance_of_tornado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7804824638e0e6e97ebe5a252806d51a4e5cac2c"
   },
   "outputs": [],
   "source": [
    "chance_of_tornado = 0.01\n",
    "\n",
    "tornado_events = np.random.binomial(1, chance_of_tornado, 1000000)\n",
    "    \n",
    "two_days_in_a_row = 0\n",
    "for j in range(1,len(tornado_events)-1):\n",
    "    if tornado_events[j]==1 and tornado_events[j-1]==1:\n",
    "        two_days_in_a_row+=1\n",
    "\n",
    "print('{} tornadoes back to back in {} years'.format(two_days_in_a_row, 1000000/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4583c0a0ec05e914af1c01e2c901da41828ad653"
   },
   "outputs": [],
   "source": [
    "np.random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "365cfd6e6602f46bc98c13d10a47ad1d98af978e"
   },
   "outputs": [],
   "source": [
    "np.random.normal(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8091adda4fbdccffb73424476c68a7aa0fb53c9a"
   },
   "outputs": [],
   "source": [
    "distribution = np.random.normal(0.75,size=1000)\n",
    "\n",
    "np.sqrt(np.sum((np.mean(distribution)-distribution)**2)/len(distribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9eed1ac016763a69de465e82736d30d7e5b1d028"
   },
   "outputs": [],
   "source": [
    "np.std(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ab89e527fcd900577d879b50272d400ae0bdbaa0"
   },
   "outputs": [],
   "source": [
    "\n",
    "stats.kurtosis(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c974e2563460f9b4942ab8c9b1d1783479779fa5"
   },
   "outputs": [],
   "source": [
    "stats.skew(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "de01fc7f82016eeb5f3b206788e7213ad373a441"
   },
   "outputs": [],
   "source": [
    "chi_squared_df2 = np.random.chisquare(2, size=10000)\n",
    "stats.skew(chi_squared_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d8cce6278eaf4b4865efebf34dfb4ec2d9b684ca"
   },
   "outputs": [],
   "source": [
    "chi_squared_df5 = np.random.chisquare(5, size=10000)\n",
    "stats.skew(chi_squared_df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1c30298fc2dcd63dface93cb1626c5e7367d4698"
   },
   "outputs": [],
   "source": [
    "output = plt.hist([chi_squared_df2,chi_squared_df5], bins=50, histtype='step', \n",
    "                  label=['2 degrees of freedom','5 degrees of freedom'])\n",
    "plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7653d84bad68f6370b1bdf484a2e9b6fb5982977"
   },
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "## 3- Pandas:The DataFrame Data Structure\n",
    " You'll hone your pandas skills by learning how to organize, reshape, and aggregate multiple data sets to answer your specific questions.\n",
    " **Pandas**:\n",
    "Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). Arithmetic operations align on both row and column labels. Can be thought of as a dict-like container for Series objects. The primary pandas data structure.\n",
    "\n",
    "Pandas is capable of many tasks including:\n",
    "\n",
    "Reading/writing many different data formats\n",
    "Selecting subsets of data\n",
    "Calculating across rows and down columns\n",
    "Finding and filling missing data\n",
    "Applying operations to independent groups within the data\n",
    "Reshaping data into different forms\n",
    "Combing multiple datasets together\n",
    "Advanced time-series functionality\n",
    "Visualization through matplotlib and seaborn\n",
    "Although pandas is very capable, it does not provide functionality for the entire data science pipeline. Pandas is typically the intermediate tool used for data exploration and cleaning squashed between data capturing and storage, and data modeling and predicting.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e82246f590c37992f9190583cdb0035d93c0dcd"
   },
   "outputs": [],
   "source": [
    "\n",
    "purchase_1 = pd.Series({'Name': 'Chris',\n",
    "                        'Item Purchased': 'Dog Food',\n",
    "                        'Cost': 22.50})\n",
    "purchase_2 = pd.Series({'Name': 'Kevyn',\n",
    "                        'Item Purchased': 'Kitty Litter',\n",
    "                        'Cost': 2.50})\n",
    "purchase_3 = pd.Series({'Name': 'Vinod',\n",
    "                        'Item Purchased': 'Bird Seed',\n",
    "                        'Cost': 5.00})\n",
    "df = pd.DataFrame([purchase_1, purchase_2, purchase_3], index=['Store 1', 'Store 1', 'Store 2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "835c6bb2dba772d11345bb2d5e40a992999d31b6"
   },
   "outputs": [],
   "source": [
    "df.loc['Store 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b48c39ad30936af6ce6932597073451c6b2bac9"
   },
   "outputs": [],
   "source": [
    "type(df.loc['Store 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c929565dc25461fd914c756431df400e6cdf058b"
   },
   "outputs": [],
   "source": [
    "df.loc['Store 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a11d22702f1be476a4d443cf811fe0a07a5dbbe4"
   },
   "outputs": [],
   "source": [
    "df.loc['Store 1', 'Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "adb35d3ac7e00c00ced7236aa7c3eaab3c85e675"
   },
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e478aabe2d50b04f5bd9cca220150476adc8b1f"
   },
   "outputs": [],
   "source": [
    "df.T.loc['Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ed1c53b43bb00bc07a95642071be8ef2b5aa779"
   },
   "outputs": [],
   "source": [
    "df['Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "084454d6fcc47a738808b0c832d59aebc49be70c"
   },
   "outputs": [],
   "source": [
    "df.loc['Store 1']['Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fdbddb30cb59ed8462a07795aaadbcd9ad2b1aa4"
   },
   "outputs": [],
   "source": [
    "df.loc[:,['Name', 'Cost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2541e9071816bd8f496ddf62b77cccb8fe325fbc"
   },
   "outputs": [],
   "source": [
    "df.drop('Store 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5fa5a22b81b92bae274d3a9afd76283ded17b478"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "918e58d124508bd5edff0ed84ba6a4c252cdec3d"
   },
   "outputs": [],
   "source": [
    "copy_df = df.copy()\n",
    "copy_df = copy_df.drop('Store 1')\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e3830ddb755492607166e3975ac6e18c9436422"
   },
   "outputs": [],
   "source": [
    "copy_df.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "946e48754fa8ed9914ef62b1c7049260861098db"
   },
   "outputs": [],
   "source": [
    "del copy_df['Name']\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de93b5c96c8b546bfb01b57d75347f5045ea01d1"
   },
   "outputs": [],
   "source": [
    "df['Location'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42414bc5b478108d59aaf9b5dff463c95904097d"
   },
   "outputs": [],
   "source": [
    "costs = df['Cost']\n",
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76922dc612283caa9821f793abac91dad9328c75"
   },
   "outputs": [],
   "source": [
    "costs+=2\n",
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ea1881948d05207d7dc2e1805c446adfa544959"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d339cee9608b148762d7ad3068c362bbc9454f7"
   },
   "source": [
    "<a id=\"31\"></a> <br>\n",
    "# 3-1 Pandas:Dataframe Indexing and Loading\n",
    "\n",
    "As a Data Scientist, you'll often find that the data you need is not in a single file. It may be spread across a number of text files, spreadsheets, or databases. You want to be able to import the data of interest as a collection of DataFrames and figure out how to combine them to answer your central questions.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53fa2f4cb18784de6d077871a606dcf5b1511862"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01a8c7bc0a10635dc10dd56ba6edcbe595013772"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffb1b09a5a8953e7dae65425890b652c214b1fb5"
   },
   "outputs": [],
   "source": [
    "# Querying a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "258b2c7201efba77d84b92286bbe69a6af240ca8"
   },
   "outputs": [],
   "source": [
    "df['SalePrice'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "739f5037a2fcdd548abc5e68f5abcba3fcdb68e4"
   },
   "outputs": [],
   "source": [
    "only_SalePrice = df.where(df['SalePrice'] > 0)\n",
    "only_SalePrice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e420645f2daa14d2bf12b3370438b5c1741f5c52"
   },
   "outputs": [],
   "source": [
    "only_SalePrice['SalePrice'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c3561ac4d86a22f3984b11ebe1200100fc95417"
   },
   "outputs": [],
   "source": [
    "df['SalePrice'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86e547ab11dacd87ccfe4657f8eb11fd9fcf3fef"
   },
   "outputs": [],
   "source": [
    "only_SalePrice = only_SalePrice.dropna()\n",
    "only_SalePrice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf0829126fff5c075151fcc5418bbe9b945c14c9"
   },
   "outputs": [],
   "source": [
    "only_SalePrice = df[df['SalePrice'] > 0]\n",
    "only_SalePrice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b957eae6c82a982ff9672d321deadf637aa421c"
   },
   "outputs": [],
   "source": [
    "len(df[(df['SalePrice'] > 0) | (df['SalePrice'] > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d076fe5f6dade0e49c2a35c7f9c64baeaf42a59d"
   },
   "outputs": [],
   "source": [
    "df[(df['SalePrice'] > 0) & (df['SalePrice'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "717b27412a1a852c84f820272d8bf94a45022aca"
   },
   "source": [
    "<a id=\"311\"></a> <br>\n",
    "## 3-1-1 Indexing Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "822efde2bbb058575dea289d057368d1af7d1394"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b11ed5fbe0e8d35b303125afc78b04abf4dc0190"
   },
   "outputs": [],
   "source": [
    "df['SalePrice'] = df.index\n",
    "df = df.set_index('SalePrice')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4848977e538e02e0444862e632101a9d6bc97742"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5da1a958ccd43f5f5427415dc8682ccbbd589b3d"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/titanic/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9c818adf02056d59d534e4cb790dd6ce74c2b861"
   },
   "outputs": [],
   "source": [
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c1adb2169bf24831daaa59655083e069d5fda4a5"
   },
   "outputs": [],
   "source": [
    "df=df[df['Age'] == 50]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94d2eb99802e00e342e3a046f9b26a06a3c501a7"
   },
   "source": [
    "<a id=\"32\"></a> <br>\n",
    "# 3-2 Pandas:Missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6946487c3ba7a29af57472c6fe03cde0ababd341"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/titanic/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "30cc0a09aa17b60a69ddccebbc0b6ceaf6077bfb"
   },
   "outputs": [],
   "source": [
    "df.fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "be537539e67066ad45f9217988aa7ca7c23a370b"
   },
   "outputs": [],
   "source": [
    "df = df.set_index('PassengerId')\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d2681f382b87e0eb47c41745576c2d35a8f55f5b"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df.set_index(['PassengerId', 'Survived'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "bea1dfdc973fe52315d701fecb6abb28edaecb81"
   },
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d79a17c1a5930de30ef9c238bf143cfc9962d24f"
   },
   "source": [
    "<a id=\"33\"></a> <br>\n",
    "# 3-3 Pandas :Merging Dataframes\n",
    "pandas provides various facilities for easily combining together Series, DataFrame, and Panel objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4809bb7be74c5ef657c069446ecffb409937f952"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{'Name': 'MJ', 'Item Purchased': 'Sponge', 'Cost': 22.50},\n",
    "                   {'Name': 'Kevyn', 'Item Purchased': 'Kitty Litter', 'Cost': 2.50},\n",
    "                   {'Name': 'Filip', 'Item Purchased': 'Spoon', 'Cost': 5.00}],\n",
    "                  index=['Store 1', 'Store 1', 'Store 2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f30d304abf7b7345a4e6e7c1105e190dd1a621d2"
   },
   "outputs": [],
   "source": [
    "df['Date'] = ['December 1', 'January 1', 'mid-May']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "fbedab0057046e0510dd1331f03ffc18c9ba520b"
   },
   "outputs": [],
   "source": [
    "df['Delivered'] = True\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8ed708570d219bad3637b3a907bb0a00be33b939"
   },
   "outputs": [],
   "source": [
    "df['Feedback'] = ['Positive', None, 'Negative']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "fc549de9e14ccf0504553ee8960442180ba895b0"
   },
   "outputs": [],
   "source": [
    "adf = df.reset_index()\n",
    "adf['Date'] = pd.Series({0: 'December 1', 2: 'mid-May'})\n",
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "80e056750b87aa3d692e6f3aa07ca4e40ce05512"
   },
   "outputs": [],
   "source": [
    "staff_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR'},\n",
    "                         {'Name': 'Sally', 'Role': 'Course liasion'},\n",
    "                         {'Name': 'James', 'Role': 'Grader'}])\n",
    "staff_df = staff_df.set_index('Name')\n",
    "student_df = pd.DataFrame([{'Name': 'James', 'School': 'Business'},\n",
    "                           {'Name': 'Mike', 'School': 'Law'},\n",
    "                           {'Name': 'Sally', 'School': 'Engineering'}])\n",
    "student_df = student_df.set_index('Name')\n",
    "print(staff_df.head())\n",
    "print()\n",
    "print(student_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c0e141f46ea59c406f9c75a501139d808720bea6"
   },
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "117f0b5ad0687b45deead65bfd2cd2e2b42aec7a"
   },
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0fcc1d0780a0b786ffbb77e88a1e1bdc5f415a4a"
   },
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d2492a6a8108c115d1f9c980a8b01242cc695a37"
   },
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='right', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7876e8102392731c7d48123c8c5dced6693a32d2"
   },
   "outputs": [],
   "source": [
    "staff_df = staff_df.reset_index()\n",
    "student_df = student_df.reset_index()\n",
    "pd.merge(staff_df, student_df, how='left', left_on='Name', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "08c724f0bf11154a1244924bd7ca0b195fff3a21"
   },
   "outputs": [],
   "source": [
    "staff_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR', 'Location': 'State Street'},\n",
    "                         {'Name': 'Sally', 'Role': 'Course liasion', 'Location': 'Washington Avenue'},\n",
    "                         {'Name': 'James', 'Role': 'Grader', 'Location': 'Washington Avenue'}])\n",
    "student_df = pd.DataFrame([{'Name': 'James', 'School': 'Business', 'Location': '1024 Billiard Avenue'},\n",
    "                           {'Name': 'Mike', 'School': 'Law', 'Location': 'Fraternity House #22'},\n",
    "                           {'Name': 'Sally', 'School': 'Engineering', 'Location': '512 Wilson Crescent'}])\n",
    "pd.merge(staff_df, student_df, how='left', left_on='Name', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "da1dc7a2a97543ef9d338dd45fc74b8e66f6221e"
   },
   "outputs": [],
   "source": [
    "staff_df = pd.DataFrame([{'First Name': 'Kelly', 'Last Name': 'Desjardins', 'Role': 'Director of HR'},\n",
    "                         {'First Name': 'Sally', 'Last Name': 'Brooks', 'Role': 'Course liasion'},\n",
    "                         {'First Name': 'James', 'Last Name': 'Wilde', 'Role': 'Grader'}])\n",
    "student_df = pd.DataFrame([{'First Name': 'James', 'Last Name': 'Hammond', 'School': 'Business'},\n",
    "                           {'First Name': 'Mike', 'Last Name': 'Smith', 'School': 'Law'},\n",
    "                           {'First Name': 'Sally', 'Last Name': 'Brooks', 'School': 'Engineering'}])\n",
    "staff_df\n",
    "student_df\n",
    "pd.merge(staff_df, student_df, how='inner', left_on=['First Name','Last Name'], right_on=['First Name','Last Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c47476edc934d4d851254db98b156de91018a0c8"
   },
   "source": [
    "<a id=\"34\"></a> <br>\n",
    "# 3-4 Idiomatic Pandas: Making Code Pandorable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2cd537dc9b3bd93a924d808ef8d6377853dae984"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../input/titanic/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6ec456b0ba8db3f621911ad4c3a36008b04cfc7f"
   },
   "outputs": [],
   "source": [
    "df = df[df['Age']==50]\n",
    "df.set_index(['PassengerId','Survived'], inplace=True)\n",
    "df.rename(columns={'Pclass': 'pclass'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef246335b484cd563b29cafd6c178820c04a6f0f"
   },
   "source": [
    "<a id=\"35\"></a> <br>\n",
    "## 3-5 Pandas :Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b45f3ee990bce0101774749b4b81e24b81911ad6"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../input/titanic/train.csv')\n",
    "df = df[df['Age']==50]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1c9afa54368039e6439950f57d39e5e0ae1faf7a"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "49994af42a822d8e0ad579866d12fdcd3a7b65ba"
   },
   "source": [
    "<a id=\"36\"></a> <br>\n",
    "## 3-6 Pandas:Scales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ef0c2c453afcd5f43e37f27dd3dccd01aa7e33c0"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D'],\n",
    "                  index=['excellent', 'excellent', 'excellent', 'good', 'good', 'good', 'ok', 'ok', 'ok', 'poor', 'poor'])\n",
    "df.rename(columns={0: 'Grades'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "cc490b8a1f851253430185eaab0d8a5ac1b843b8"
   },
   "outputs": [],
   "source": [
    "df['Grades'].astype('category').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "388f3454ed9fcc1b88c898e329c0c2d4b062df1f"
   },
   "outputs": [],
   "source": [
    "grades = df['Grades'].astype('category',\n",
    "                             categories=['D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+'],\n",
    "                             ordered=True)\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "51a0c5d18dbc6c395b900c34e9e590591d671676"
   },
   "outputs": [],
   "source": [
    "grades > 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d08b78789267689bc4055c5c31144abe8ef2627"
   },
   "source": [
    "<a id=\"361\"></a> <br>\n",
    "## 3-6-1 pandas: Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "167c3326d2d423019e34b24ed144a3c8ef786c31"
   },
   "source": [
    "To select rows whose column value equals a scalar, some_value, use ==:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "60af3162523bec271c26fa1c464775e63564f031"
   },
   "outputs": [],
   "source": [
    "df.loc[df['Grades'] == 'A+']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "616ff06c8b09a1a3b836fddcf3ff95112d9eec2a"
   },
   "source": [
    "To select rows whose column value is in an iterable, some_values, use **isin**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6c3033e7a4c1124cc2238c021a933ad819d3a048"
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})\n",
    "df_test.isin({'A': [1, 3], 'B': [4, 7, 12]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a7c669be723faf14ca7fc8b05501ebd498da8fe8"
   },
   "source": [
    "Combine multiple conditions with &:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7d5c19fe1055ae6c2c68c5aae516c35483df55e9"
   },
   "outputs": [],
   "source": [
    "df.loc[(df['Grades'] == 'A+') & (df['Grades'] == 'D')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a436ef9ed699a1c2408c46194514162b3868f81"
   },
   "source": [
    "To select rows whose column value does not equal some_value, use !=:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e81acca64ad8aa664b566cf95000a85c27b3019d"
   },
   "outputs": [],
   "source": [
    "\n",
    "df.loc[df['Grades'] != 'B+']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd225a2c3d4527356236ec4e67edcc339c16c82f"
   },
   "source": [
    "isin returns a boolean Series, so to select rows whose value is not in some_values, negate the boolean Series using ~:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "96079c5d5cb5850d5f09c865f9729f0e225cc5ac"
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3003f67ee4c4b864a65f8d5203a7b38b068cfa48"
   },
   "outputs": [],
   "source": [
    "df_test.loc[~df_test['A'].isin({'A': [1, 3], 'B': [4, 7, 12]})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d205d889ce4d23e00f2ced7864c044e9d3d3ec84"
   },
   "source": [
    "<a id=\"37\"></a> <br>\n",
    "## 3-7 Pandas:Date Functionality\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a466f75d44bdabf52ddb21d0c173d9421afce7d9"
   },
   "source": [
    "<a id=\"371\"></a> <br>\n",
    "### 3-7-1 Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "80a449e3cac139ac3b9697dba331363538a1a65f"
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('9/1/2016 10:05AM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c39545f2495d3f837c6b75dfd57b1a53c3d27d75"
   },
   "source": [
    "<a id=\"372\"></a> <br>\n",
    "### 3-7-2 Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3c160f45b74a5e4faecbf6661978e9c59e933e14"
   },
   "outputs": [],
   "source": [
    "pd.Period('1/2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "124c5a5ba7872ab55b3cd1fbbe18669747124eea"
   },
   "outputs": [],
   "source": [
    "pd.Period('3/5/2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f19b87e81ba7aa0d8adb850d75d9452cf3a73ddf"
   },
   "source": [
    "<a id=\"373\"></a> <br>\n",
    "### 3-7-3 DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "68a99def5b8fbd9839cf35667a3481ed23c476c0"
   },
   "outputs": [],
   "source": [
    "t1 = pd.Series(list('abc'), [pd.Timestamp('2016-09-01'), pd.Timestamp('2016-09-02'), pd.Timestamp('2016-09-03')])\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "073eeeb51e53b50660a822eb7484d4e8b72a7dfa"
   },
   "outputs": [],
   "source": [
    "type(t1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c891236e512838ed6088e02c88dd888029b226a3"
   },
   "source": [
    "<a id=\"374\"></a> <br>\n",
    "### 3-7-4 PeriodIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5a19abe4e4a7324a8f7565c66f8270ab9eb3cae6"
   },
   "outputs": [],
   "source": [
    "t2 = pd.Series(list('def'), [pd.Period('2016-09'), pd.Period('2016-10'), pd.Period('2016-11')])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "522200c3bbb47e10177f1c63a0ed3bfb49cbcf47"
   },
   "outputs": [],
   "source": [
    "type(t2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50e147a4abff8fd3014f3fb2a105f516b4a5ea2f"
   },
   "source": [
    "<a id=\"38\"></a> <br>\n",
    "## 3-8 Pandas: Converting to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "862d2bc5c5b430ed2be1292b9d3b5efe8a3c9cc1"
   },
   "outputs": [],
   "source": [
    "d1 = ['2 June 2013', 'Aug 29, 2014', '2015-06-26', '7/12/16']\n",
    "ts3 = pd.DataFrame(np.random.randint(10, 100, (4,2)), index=d1, columns=list('ab'))\n",
    "ts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "840963eeb8ca7bfe0a5d3167211e74d48446fe3a"
   },
   "outputs": [],
   "source": [
    "ts3.index = pd.to_datetime(ts3.index)\n",
    "ts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e2482002fae0947549bdd81a3da93c8e0cde40fe"
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('4.7.12', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "cae5847092e33cba7b657a90810a7ef35ae307e4"
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('9/3/2016')-pd.Timestamp('9/1/2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c54a7d88507df86710fc585582b2074cb8d5aa5a"
   },
   "source": [
    "<a id=\"381\"></a> <br>\n",
    "### 3-8-1 Timedeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "fe333509538c1ec2bf81fda4613344cfa699b410"
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('9/3/2016')-pd.Timestamp('9/1/2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "08e10cce4428eaa329eb84677c755b0307488bfa"
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('9/2/2016 8:10AM') + pd.Timedelta('12D 3H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a73485dcf7310c754e69ab5ed802d7e466684242"
   },
   "source": [
    "<a id=\"382\"></a> <br>\n",
    "### 3-8-2 Working with Dates in a Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f5bcbc00ce23e50d346495588428e5d6f430a8df"
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('10-01-2016', periods=9, freq='2W-SUN')\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "41df9aeeb10a2d404f1eada62b4a4066e0f37af0"
   },
   "outputs": [],
   "source": [
    "df.index.ravel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f9a265dce077fd183b2172378a85ed2d23290189"
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cedecea930b278f86292367cc28d2996a235a169"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e80040de557789b0dff267ce45ba3e494885fee"
   },
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "# 4- Sklearn \n",
    "- The __open source__ Python ecosystem provides __a standalone, versatile and powerful scientific working environment__, including: [NumPy](http://numpy.org), [SciPy](http://scipy.org), [IPython](http://ipython.org), [Matplotlib](http://matplotlib.org), [Pandas](http://pandas.pydata.org/), _and many others..._\n",
    "\n",
    "\n",
    "\n",
    "- Scikit-Learn builds upon NumPy and SciPy and __complements__ this scientific environment with machine learning algorithms;\n",
    "- By design, Scikit-Learn is __non-intrusive__, easy to use and easy to combine with other libraries;\n",
    "- Core algorithms are implemented in low-level languages.\n",
    "\n",
    "## 4-1 Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "666c206f83175114a513b37fb9ae322b5cd8543e"
   },
   "source": [
    "**Supervised learning**:\n",
    "\n",
    "1. Linear models (Ridge, Lasso, Elastic Net, ...)\n",
    "1. Support Vector Machines\n",
    "1. Tree-based methods (Random Forests, Bagging, GBRT, ...)\n",
    "1. Nearest neighbors \n",
    "1. Neural networks (basics)\n",
    "1. Gaussian Processes\n",
    "1. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44eef8d741beebe15555c5166360b2ce77f5d5b1"
   },
   "source": [
    "**Unsupervised learning**:\n",
    "\n",
    "1. Clustering (KMeans, Ward, ...)\n",
    "1. Matrix decomposition (PCA, ICA, ...)\n",
    "1. Density estimation\n",
    "1. Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8da2cc5428b697a7b5f21d34038d343bb8b094bb"
   },
   "source": [
    "__Model selection and evaluation:__\n",
    "\n",
    "1. Cross-validation\n",
    "1. Grid-search\n",
    "1. Lots of metrics\n",
    "\n",
    "_... and many more!_ (See our [Reference](http://scikit-learn.org/dev/modules/classes.html))\n",
    "<a id=\"42\"></a> <br>\n",
    "## 4-2 Data Collection\n",
    "**Data collection** is the process of gathering and measuring data, information or any variables of interest in a standardized and established manner that enables the collector to answer or test hypothesis and evaluate outcomes of the particular collection.[techopedia]\n",
    "\n",
    "**Iris dataset**  consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray\n",
    "\n",
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.[6]\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9269ae851b744856bce56840637030a16a5877e1"
   },
   "outputs": [],
   "source": [
    "# import Dataset to play with it\n",
    "iris = pd.read_csv('../input/iris-dataset/Iris.csv')\n",
    "train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
    "test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58ed9c838069f54de5cf90b20a774c3e236149b3"
   },
   "source": [
    "**<< Note 1 >>**\n",
    "\n",
    "* Each row is an observation (also known as : sample, example, instance, record)\n",
    "* Each column is a feature (also known as: Predictor, attribute, Independent Variable, input, regressor, Covariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b5fd1034cd591ebd29fba1c77d342ec2b408d13"
   },
   "source": [
    "After loading the data via **pandas**, we should checkout what the content is, description and via the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "edd043f8feb76cfe51b79785302ca4936ceb7b51"
   },
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8a877d51d20c1ad31bb635cffc89175426eb77c"
   },
   "source": [
    "<a id=\"43\"></a> <br>\n",
    "# 4-3 Framework\n",
    "\n",
    "Data comes as a finite learning set ${\\cal L} = (X, y)$ where\n",
    "* Input samples are given as an array $X$ of shape `n_samples` $\\times$ `n_features`, taking their values in ${\\cal X}$;\n",
    "* Output values are given as an array $y$, taking _symbolic_ values in ${\\cal Y}$.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bafb45df9ecfe90563f2f9a1be8a327823cf6d35"
   },
   "source": [
    "The goal of supervised classification is to build an estimator $\\varphi: {\\cal X} \\mapsto {\\cal Y}$ minimizing\n",
    "\n",
    "$$\n",
    "Err(\\varphi) = \\mathbb{E}_{X,Y}\\{ \\ell(Y, \\varphi(X)) \\}\n",
    "$$\n",
    "\n",
    "where $\\ell$ is a loss function, e.g., the zero-one loss for classification $\\ell_{01}(Y,\\hat{Y}) = 1(Y \\neq \\hat{Y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7efef8f514caf78e7bc2a60b4d5c0e7fa6d160ac"
   },
   "source": [
    "<a id=\"44\"></a> <br>\n",
    "# 4-4 Applications\n",
    "\n",
    "1. **Classifying** signal from background events; \n",
    "1. **Diagnosing** disease from symptoms;\n",
    "1. **Recognising** cats in pictures;\n",
    "1. **Identifying** body parts with Kinect cameras;\n",
    "- ...\n",
    "  ###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cc13baab79cbc6446763e4ebe8feba2c95e74c9"
   },
   "source": [
    "<a id=\"45\"></a> <br>\n",
    "# 4-5 How to use Sklearn Data Set? \n",
    "\n",
    "- Input data = Numpy arrays or Scipy sparse matrices ;\n",
    "- Algorithms are expressed using high-level operations defined on matrices or vectors (similar to MATLAB) ;\n",
    "    - Leverage efficient low-leverage implementations ;\n",
    "    - Keep code short and readable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ea74e169f182b48bc12abc501df217e7c711157c"
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "X, y = make_blobs(n_samples=1000, centers=20, random_state=123)\n",
    "labels = [\"b\", \"r\"]\n",
    "y = np.take(labels, (y < 10))\n",
    "print(X) \n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9430d1ac40a1d7ba715347c27039b9b0859e674a"
   },
   "outputs": [],
   "source": [
    "# X is a 2 dimensional array, with 1000 rows and 2 columns\n",
    "print(X.shape)\n",
    " \n",
    "# y is a vector of 1000 elements\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0e4d94f4cde57a7f8aeaec876d0020b144fd7818"
   },
   "outputs": [],
   "source": [
    "# Rows and columns can be accessed with lists, slices or masks\n",
    "print(X[[1, 2, 3]])     # rows 1, 2 and 3\n",
    "print(X[:5])            # 5 first rows\n",
    "print(X[500:510, 0])    # values from row 500 to row 510 at column 0\n",
    "print(X[y == \"b\"][:5])  # 5 first rows for which y is \"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f87a77afd2c6d75c7d20390394a1f9ae569a30dc"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.max_open_warning\"] = -1\n",
    "plt.figure()\n",
    "for label in labels:\n",
    "    mask = (y == label)\n",
    "    plt.scatter(X[mask, 0], X[mask, 1], c=label)\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-10, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "71b52d10786896ab758025f670f7dc5c80db03a4"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "data.target[[10, 80, 140]]\n",
    "list(data.target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af3faf3d05bc406b6d882f527f5f5637c4e572a8"
   },
   "source": [
    "<a id=\"46\"></a> <br>\n",
    "# 4-6 Loading external data\n",
    "\n",
    "1. Numpy provides some [simple tools](https://docs.scipy.org/doc/numpy/reference/routines.io.html) for loading data from files (CSV, binary, etc);\n",
    "\n",
    "1. For structured data, Pandas provides more [advanced tools](http://pandas.pydata.org/pandas-docs/stable/io.html) (CSV, JSON, Excel, HDF5, SQL, etc);\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db67b8ed29fd65ec13569321eb9aed2edb1fec80"
   },
   "source": [
    "<a id=\"47\"></a> <br>\n",
    "## 4-7 what is new?\n",
    "A new clustering algorithm: cluster.**OPTICS**: an algoritm related to cluster.**DBSCAN**, that has hyperparameters easier to set and that scales better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5294a607209dc1d413e84d9e182334a41fa5ee08"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "X = np.array([[1, 2], [2, 2], [2, 3],[8, 7], [8, 8], [25, 80]])\n",
    "clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8e49459a594753031d57b263ee211615e978c04f"
   },
   "outputs": [],
   "source": [
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a409afb829be4b4c983398fdd08b816fefd50331"
   },
   "outputs": [],
   "source": [
    "clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "722d3cb2f6784dc78d5c800492bbde2594c2211f"
   },
   "source": [
    "<a id=\"48\"></a> <br>\n",
    "## 4-8 Tip & Trick\n",
    "In this section we gather some useful advice and tools that may increase your quality-of-life when reviewing pull requests, running unit tests, and so forth. Some of these tricks consist of userscripts that require a browser extension such as TamperMonkey or GreaseMonkey; to set up userscripts you must have one of these extensions installed, enabled and running. We provide userscripts as GitHub gists; to install them, click on the “Raw” button on the gist page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50c34f49740671a08c044f413ec1a258b81da727"
   },
   "source": [
    "<a id=\"481\"></a> <br>\n",
    "### 4-8-1 Profiling Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8ecd1c1a327756d112f562d05e894031cd498133"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import load_digits\n",
    "X = load_digits().data\n",
    "%timeit NMF(n_components=16, tol=1e-2).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72cc7c7b60a33390a85b16bc34e3b9e424650cdd"
   },
   "source": [
    "<a id=\"49\"></a> <br>\n",
    "# 4-9 Model Deployment\n",
    "All learning algorithms in scikit-learn share a uniform and limited API consisting of complementary interfaces:\n",
    "\n",
    "1. an `estimator` interface for building and fitting models;\n",
    "1. a `predictor` interface for making predictions;\n",
    "1. a `transformer` interface for converting data.\n",
    "\n",
    "Goal: enforce a simple and consistent API to __make it trivial to swap or plug algorithms__. \n",
    "\n",
    "In this section have been applied more than **20 learning algorithms** that play an important rule in your experiences and improve your knowledge in case of using sklearn.\n",
    "\n",
    "> **<< Note 3 >>** : The results shown here may be slightly different for your analysis because, for example, the neural network algorithms use random number generators for fixing the initial value of the weights (starting points) of the neural networks, which often result in obtaining slightly different (local minima) solutions each time you run the analysis. Also note that changing the seed for the random number generator used to create the train, test, and validation samples can change your results.\n",
    "\n",
    "  ###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b7788bbaaace438242d3b2d0d2ed489a91939ce"
   },
   "source": [
    "<a id=\"410\"></a> <br>\n",
    "## 4-10  Families of ML algorithms\n",
    "There are several categories for machine learning algorithms, below are some of these categories:\n",
    "<img src='https://i.stack.imgur.com/rLN4Z.png'>\n",
    "* Linear\n",
    "    * Linear Regression\n",
    "    * Logistic Regression\n",
    "    * Support Vector Machines\n",
    "* Tree-Based\n",
    "    * Decision Tree\n",
    "    * Random Forest\n",
    "    * GBDT\n",
    "* KNN\n",
    "* Neural Networks\n",
    "\n",
    "-----------------------------\n",
    "And if we  want to categorize ML algorithms with the type of learning, there are below type:\n",
    "* Classification\n",
    "\n",
    "    * k-Nearest \tNeighbors\n",
    "    * LinearRegression\n",
    "    * SVM\n",
    "    * DT \n",
    "    * NN\n",
    "    \n",
    "* clustering\n",
    "\n",
    "    * K-means\n",
    "    * HCA\n",
    "    * Expectation Maximization\n",
    "    \n",
    "* Visualization \tand\tdimensionality \treduction:\n",
    "\n",
    "    * Principal \tComponent \tAnalysis(PCA)\n",
    "    * Kernel PCA\n",
    "    * Locally -Linear\tEmbedding \t(LLE)\n",
    "    * t-distributed\tStochastic\tNeighbor\tEmbedding \t(t-SNE)\n",
    "    \n",
    "* Association \trule\tlearning\n",
    "\n",
    "    * Apriori\n",
    "    * Eclat\n",
    "* Semisupervised learning\n",
    "* Reinforcement Learning\n",
    "    * Q-learning\n",
    "* Batch learning & Online learning\n",
    "* Ensemble  Learning\n",
    "\n",
    "**<< Note >>**\n",
    "> Here is no method which outperforms all others for all tasks\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "daf9910caba26e071ff560dbdaca079ee148e140"
   },
   "source": [
    "<a id=\"411\"></a> <br>\n",
    "## 4-11 Prepare Features & Targets\n",
    "First of all seperating the data into dependent(**Feature**) and independent(**Target**) variables.\n",
    "\n",
    "**<< Note 4 >>**\n",
    "1. X==>>Feature\n",
    "1. y==>>Target\n",
    "##  Test error\n",
    "\n",
    "Issue: the training error is a __biased__ estimate of the generalization error.\n",
    "\n",
    "Solution: Divide ${\\cal L}$ into two disjoint parts called training and test sets (usually using 70% for training and 30% for test).\n",
    "1. Use the training set for fitting the model;\n",
    "1. Use the test set for evaluation only, thereby yielding an unbiased estimate.\n",
    "\n",
    "  ###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b06cb1191a0f52a904c52a918d1f999536e79bda"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = iris.iloc[:, :-1].values\n",
    "y = iris.iloc[:, -1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d13f167dd92888d856c4ad2ff2895bf4855e361c"
   },
   "source": [
    "<a id=\"412\"></a> <br>\n",
    "## 4-12 Accuracy and precision\n",
    "- Recall that we want to learn an estimator $\\varphi$ minimizing the generalization error $Err(\\varphi) = \\mathbb{E}_{X,Y}\\{ \\ell(Y, \\varphi(X)) \\}$.\n",
    "\n",
    "- Problem: Since $P_{X,Y}$ is unknown, the generalization error $Err(\\varphi)$ cannot be evaluated.\n",
    "\n",
    "- Solution: Use a proxy to approximate $Err(\\varphi)$.\n",
    "* **precision** : \n",
    "\n",
    "In pattern recognition, information retrieval and binary classification, precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, \n",
    "* **recall** : \n",
    "\n",
    "recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. \n",
    "* **F-score** :\n",
    "\n",
    "the F1 score is a measure of a test's accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive). The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    "**What is the difference between accuracy and precision?**\n",
    "\"Accuracy\" and \"precision\" are general terms throughout science. A good way to internalize the difference are the common \"bullseye diagrams\". In machine learning/statistics as a whole, accuracy vs. precision is analogous to bias vs. variance.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc2471a2bc5d24fbee0532a71219e8b25996c20c"
   },
   "source": [
    "<a id=\"413\"></a> <br>\n",
    "## 4-13 Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ae2c9909a05b213a567338be03f0b880dcbc42fd"
   },
   "outputs": [],
   "source": [
    "class Estimator(object):\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fits estimator to data.\"\"\"\n",
    "        # set state of ``self``\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c7c25b799b47dd172f3f73e2c85d2670b0095124"
   },
   "outputs": [],
   "source": [
    "# Import the nearest neighbor class\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Change this to try \n",
    "                                                    # something else\n",
    "\n",
    "# Set hyper-parameters, for controlling algorithm\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Learn a model from training data\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f3813605cc909c6fecd52a12e2edc37ad4cc42c2"
   },
   "outputs": [],
   "source": [
    "# Estimator state is stored in instance attributes\n",
    "clf._tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0984dea25e9a6c6c7b7372057f87c4bacd230375"
   },
   "source": [
    "<a id=\"414\"></a> <br>\n",
    "## 4-14 Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9ca84979bfe46e0b6ce79ade03ac19efde72f5c3"
   },
   "outputs": [],
   "source": [
    "# Make predictions  \n",
    "print(clf.predict(X[:5])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1b12ceaf8ca499e5e7d3486955f281f5bd72f34b"
   },
   "outputs": [],
   "source": [
    "# Compute (approximate) class probabilities\n",
    "print(clf.predict_proba(X[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84079ff3031fe25f5454233a5e2e1ba97030403d"
   },
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "## 5- Feature Scaling with scikit-learn\n",
    "Feature scaling is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step[wikipedia].\n",
    "\n",
    "In this section  we explore 3 methods of feature scaling that are implemented in scikit-learn:\n",
    "1. StandardScaler\n",
    "1. MinMaxScaler\n",
    "1. RobustScaler\n",
    "1. Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c2f614f35b51dee635551e0e8895a88c002e230"
   },
   "source": [
    "<a id=\"51\"></a> <br>\n",
    "## 5-1 Standard Scaler\n",
    "The StandardScaler assumes your data is normally distributed within each feature and will scale them such that the distribution is now centred around 0, with a standard deviation of 1.\n",
    "\n",
    "The mean and standard deviation are calculated for the feature and then the feature is scaled based on:\n",
    "\n",
    "$xi–$mean(x)/ $stdev(x)\n",
    "If data is not normally distributed, this is not the best scaler to use.\n",
    "\n",
    "Let’s take a look at it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2bdc6b63329fdc6affbcb1770d9ddf790a85152a"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "df = pd.DataFrame({\n",
    "    'x1': np.random.normal(0, 2, 10000),\n",
    "    'x2': np.random.normal(5, 3, 10000),\n",
    "    'x3': np.random.normal(-5, 5, 10000)\n",
    "})\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=['x1', 'x2', 'x3'])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(6, 5))\n",
    "\n",
    "ax1.set_title('Before Scaling')\n",
    "sns.kdeplot(df['x1'], ax=ax1)\n",
    "sns.kdeplot(df['x2'], ax=ax1)\n",
    "sns.kdeplot(df['x3'], ax=ax1)\n",
    "ax2.set_title('After Standard Scaler')\n",
    "sns.kdeplot(scaled_df['x1'], ax=ax2)\n",
    "sns.kdeplot(scaled_df['x2'], ax=ax2)\n",
    "sns.kdeplot(scaled_df['x3'], ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3eda1677dbe142f72e2e8471d81260a1ee0103bb"
   },
   "source": [
    "All features are now on the same scale relative to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cfa6c616362340c78b53d941211e6dc5c85ccc88"
   },
   "source": [
    "## 3-2 Min-Max Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f825bbb80c7aa4c320af437c60e45b3d750b25af"
   },
   "source": [
    "The **MinMaxScaler** is the probably the most famous scaling algorithm, and follows the following formula for each feature:\n",
    "\n",
    "xi – min(x) / max(x) – min(x)\n",
    "\n",
    "It essentially shrinks the range such that the range is now between 0 and 1 (or -1 to 1 if there are negative values).\n",
    "\n",
    "This scaler works better for cases in which the standard scaler might not work so well. If the distribution is not Gaussian or the standard deviation is very small, the min-max scaler works better.\n",
    "\n",
    "However, it is sensitive to outliers, so if there are outliers in the data, you might want to consider the **Robust Scaler** below.\n",
    "\n",
    "For now, let’s see the min-max scaler in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b140bfc83800bbe2f2b70bad10dc182d71815b36"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    # positive skew\n",
    "    'x1': np.random.chisquare(8, 1000),\n",
    "    # negative skew \n",
    "    'x2': np.random.beta(8, 2, 1000) * 40,\n",
    "    # no skew\n",
    "    'x3': np.random.normal(50, 3, 1000)\n",
    "})\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=['x1', 'x2', 'x3'])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(6, 5))\n",
    "ax1.set_title('Before Scaling')\n",
    "sns.kdeplot(df['x1'], ax=ax1)\n",
    "sns.kdeplot(df['x2'], ax=ax1)\n",
    "sns.kdeplot(df['x3'], ax=ax1)\n",
    "ax2.set_title('After Min-Max Scaling')\n",
    "sns.kdeplot(scaled_df['x1'], ax=ax2)\n",
    "sns.kdeplot(scaled_df['x2'], ax=ax2)\n",
    "sns.kdeplot(scaled_df['x3'], ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ab92d12860f488ace4a77f50430d3053a0aacd0"
   },
   "source": [
    "Notice that the skewness of the distribution is maintained but the 3 distributions are brought into the same scale so that they overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e4d9be25e2cab0d8f938a4f31e7c790e402bd5c"
   },
   "source": [
    "## 3-3 Robust Scaler\n",
    "The RobustScaler uses a similar method to the Min-Max scaler but it instead uses the interquartile range, rathar than the min-max, so that it is robust to outliers. Therefore it follows the formula:\n",
    "\n",
    "xi–Q1(x) / Q3(x)–Q1(x)\n",
    "For each feature.\n",
    "\n",
    "Of course this means it is using the less of the data for scaling so it’s more suitable for when there are outliers in the data.\n",
    "\n",
    "Let’s take a look at this one in action on some data with outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ab8bea4c9d1c11fc0c162781dfaab2fce58085e7"
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\n",
    "    # Distribution with lower outliers\n",
    "    'x1': np.concatenate([np.random.normal(20, 1, 1000), np.random.normal(1, 1, 25)]),\n",
    "    # Distribution with higher outliers\n",
    "    'x2': np.concatenate([np.random.normal(30, 1, 1000), np.random.normal(50, 1, 25)]),\n",
    "})\n",
    "\n",
    "scaler = preprocessing.RobustScaler()\n",
    "robust_scaled_df = scaler.fit_transform(x)\n",
    "robust_scaled_df = pd.DataFrame(robust_scaled_df, columns=['x1', 'x2'])\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "minmax_scaled_df = scaler.fit_transform(x)\n",
    "minmax_scaled_df = pd.DataFrame(minmax_scaled_df, columns=['x1', 'x2'])\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(9, 5))\n",
    "ax1.set_title('Before Scaling')\n",
    "sns.kdeplot(x['x1'], ax=ax1)\n",
    "sns.kdeplot(x['x2'], ax=ax1)\n",
    "ax2.set_title('After Robust Scaling')\n",
    "sns.kdeplot(robust_scaled_df['x1'], ax=ax2)\n",
    "sns.kdeplot(robust_scaled_df['x2'], ax=ax2)\n",
    "ax3.set_title('After Min-Max Scaling')\n",
    "sns.kdeplot(minmax_scaled_df['x1'], ax=ax3)\n",
    "sns.kdeplot(minmax_scaled_df['x2'], ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bd719c9b7237082e93dba3b817f0eca88053309"
   },
   "source": [
    "Notice that after Robust scaling, the distributions are brought into the same scale and overlap, but the outliers remain outside of bulk of the new distributions.\n",
    "\n",
    "However, in Min-Max scaling, the two normal distributions are kept seperate by the outliers that are inside the 0-1 range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "265e2a384db8b8cfcfefb9a209ee91d369fe75dd"
   },
   "source": [
    "## 3-4 Normalizer\n",
    "The normalizer scales each value by dividing each value by its magnitude in n-dimensional space for n number of features.\n",
    "\n",
    "Each point is now within 1 unit of the origin on this Cartesian co-ordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "87cd95d01526e1e45bd2f283bf861477b069543d"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x1': np.random.randint(-100, 100, 1000).astype(float),\n",
    "    'y1': np.random.randint(-80, 80, 1000).astype(float),\n",
    "    'z1': np.random.randint(-150, 150, 1000).astype(float),\n",
    "})\n",
    "\n",
    "scaler = preprocessing.Normalizer()\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax1.scatter(df['x1'], df['y1'], df['z1'])\n",
    "ax2.scatter(scaled_df['x1'], scaled_df['y1'], scaled_df['z1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aeac26deaba89efb376177b4b485d212fbb5593c"
   },
   "source": [
    "Note that the points are all brought within a sphere that is at most 1 away from the origin at any point. Also, the axes that were previously different scales are now all one scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6ea122dfd9ae36afa57b216312dc87f3cd56741"
   },
   "source": [
    "## 5- Machine Learning Algorithms with scikit-learn\n",
    "In this section we will examine 20 different algorithms using this scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8b544762cc789bfeb8ebccd6765f77b9c7e1a0f"
   },
   "source": [
    "<a id=\"16\"></a> <br>\n",
    "## 5-1 K-Nearest Neighbours\n",
    "In **Machine Learning**, the **k-nearest neighbors algorithm** (k-NN) is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:\n",
    "\n",
    "In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n",
    "In k-NN regression, the output is the property value for the object. This value is the average of the values of its k nearest neighbors.\n",
    "k-NN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until classification. The k-NN algorithm is among the simplest of all machine learning algorithms.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "eaa2caacfbc319932f79c75c549364089d1e649f"
   },
   "outputs": [],
   "source": [
    "# K-Nearest Neighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Model = KNeighborsClassifier(n_neighbors=8)\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e01bbec9f80532e30c6cf26d5c3fffffb5ea01d4"
   },
   "source": [
    "<a id=\"17\"></a> <br>\n",
    "##  5-2 Radius Neighbors Classifier\n",
    "Classifier implementing a **vote** among neighbors within a given **radius**\n",
    "\n",
    "In scikit-learn **RadiusNeighborsClassifier** is very similar to **KNeighborsClassifier** with the exception of two parameters. First, in RadiusNeighborsClassifier we need to specify the radius of the fixed area used to determine if an observation is a neighbor using radius. Unless there is some substantive reason for setting radius to some value, it is best to treat it like any other hyperparameter and tune it during model selection. The second useful parameter is outlier_label, which indicates what label to give an observation that has no observations within the radius - which itself can often be a useful tool for identifying outliers.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7728fdafa163e068668cea92cf8d79306b41d458"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import  RadiusNeighborsClassifier\n",
    "Model=RadiusNeighborsClassifier(radius=8.0)\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "#summary of the predictions made by the classifier\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "#Accouracy score\n",
    "print('accuracy is ', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e55a785373bf654e0d4b2a78693fab1c8a625acb"
   },
   "source": [
    "<a id=\"18\"></a> <br>\n",
    "## 5-3 Logistic Regression\n",
    "Logistic regression is the appropriate regression analysis to conduct when the dependent variable is **dichotomous** (binary). Like all regression analyses, the logistic regression is a **predictive analysis**.\n",
    "\n",
    "In statistics, the logistic model (or logit model) is a widely used statistical model that, in its basic form, uses a logistic function to model a binary dependent variable; many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model; it is a form of binomial regression. Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass/fail, win/lose, alive/dead or healthy/sick; these are represented by an indicator variable, where the two values are labeled \"0\" and \"1\"\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "55eb348cf69272192274cd0728a123796b459b55"
   },
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Model = LogisticRegression()\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0a1c2ccaa4f6e9c5e2e42c47a295ceef7abd3b9"
   },
   "source": [
    "<a id=\"19\"></a> <br>\n",
    "##   5-4 Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d509b2111a143660dd5cb1f02ea2779e38295b77"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "Model = PassiveAggressiveClassifier()\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52938b49082dac7b35dc627828838bf12924cc7f"
   },
   "source": [
    "<a id=\"20\"></a> <br>\n",
    "## 5-5 Naive Bayes\n",
    "In machine learning, naive Bayes classifiers are a family of simple \"**probabilistic classifiers**\" based on applying Bayes' theorem with strong (naive) independence assumptions between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "522d4a3fa874950d0850a5a9a4178ec763781ec3"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "Model = GaussianNB()\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e530d18ab308e36d575806583e534cc07fe61c61"
   },
   "source": [
    "<a id=\"21\"></a> <br>\n",
    "##  5-6 BernoulliNB\n",
    "Like MultinomialNB, this classifier is suitable for **discrete data**. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e7051b5e9aa144b74e9913cb2a6668832e7f3e02"
   },
   "outputs": [],
   "source": [
    "# BernoulliNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "Model = BernoulliNB()\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "386d2d0e4fc7f5dc2b9298226d8e2ecfb7150346"
   },
   "source": [
    "<a id=\"22\"></a> <br>\n",
    "## 5-7 SVM\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "* Effective in high dimensional spaces.\n",
    "* Still effective in cases where number of dimensions is greater than the number of samples. \n",
    "* Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "* Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "* If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "* SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a44a5a43945404c95863668c2ba099f6032357f8"
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "Model = SVC()\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1d092cc03dcaa712f4fe4ec6867b292321377d5"
   },
   "source": [
    "<a id=\"23\"></a> <br>\n",
    "## 5-8 Nu-Support Vector Classification\n",
    "\n",
    "> Similar to SVC but uses a parameter to control the number of support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2fa7c9a5bef780adb400bd9ad83d030f83a8d2b3"
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine's \n",
    "from sklearn.svm import NuSVC\n",
    "\n",
    "Model = NuSVC()\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d07a75e83251ddbf8cfdfd11c9faa2671ad87ff"
   },
   "source": [
    "<a id=\"24\"></a> <br>\n",
    "## 5-9 Linear Support Vector Classification\n",
    "\n",
    "Similar to **SVC** with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7e7275f160f2e4e270200eaa01c13be5cb465142"
   },
   "outputs": [],
   "source": [
    "# Linear Support Vector Classification\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Model = LinearSVC()\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cec81c9e0c3bc6afba07811a321b5383a0f823f3"
   },
   "source": [
    "<a id=\"25\"></a> <br>\n",
    "## 5-10 Decision Tree\n",
    "Decision Trees (DTs) are a non-parametric supervised learning method used for **classification** and **regression**. The goal is to create a model that predicts the value of a target variable by learning simple **decision rules** inferred from the data features.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "10e25ad67f7c25a8654637d4ba496b64121d67d0"
   },
   "outputs": [],
   "source": [
    "# Decision Tree's\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Model = DecisionTreeClassifier()\n",
    "\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a7d897130fd705943764e924bbe468c99b7c036a"
   },
   "source": [
    "<a id=\"26\"></a> <br>\n",
    "## 5-11 ExtraTreeClassifier\n",
    "An extremely randomized tree classifier.\n",
    "\n",
    "Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the **max_features** randomly selected features and the best split among those is chosen. When max_features is set 1, this amounts to building a totally random decision tree.\n",
    "\n",
    "**Warning**: Extra-trees should only be used within ensemble methods.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5a775006a814b6aacdcc07dc46995eb291b873f1"
   },
   "outputs": [],
   "source": [
    "# ExtraTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "Model = ExtraTreeClassifier()\n",
    "\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48f940f73580a2997d75f22eba09d938c86a1a97"
   },
   "source": [
    "<a id=\"27\"></a> <br>\n",
    "## 5-12 Neural network\n",
    "\n",
    "I have used multi-layer Perceptron classifier.\n",
    "This model optimizes the log-loss function using **LBFGS** or **stochastic gradient descent**.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5f040cfaeb71f8caa94e4d7f18cccde8d2a0b8a7"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "Model=MLPClassifier()\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "# Summary of the predictions\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "#Accuracy Score\n",
    "print('accuracy is ',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ffc339dbf9c8da74194b994930694bd97bb2afbb"
   },
   "source": [
    "<a id=\"30\"></a> <br>\n",
    "## 5-13  RandomForest\n",
    "A random forest is a meta estimator that **fits a number of decision tree classifiers** on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n",
    "\n",
    "The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8ed2305b51c2248a8aa62cf4452632f448e83771"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Model=RandomForestClassifier(max_depth=2)\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "#Accuracy Score\n",
    "print('accuracy is ',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1311eb15f2afceed2219faeb859d0d07b7072176"
   },
   "source": [
    "<a id=\"31\"></a> <br>\n",
    "## 5-14 Bagging classifier \n",
    "A Bagging classifier is an ensemble **meta-estimator** that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
    "\n",
    "This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting . If samples are drawn with replacement, then the method is known as Bagging . When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces . Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches .[http://scikit-learn.org]\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c11c731d3db6c1c81301da85dc158cb7d324c4cb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "Model=BaggingClassifier()\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "#Accuracy Score\n",
    "print('accuracy is ',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0944bd32424f38906148d96f4b1e6fccfbf97a6"
   },
   "source": [
    "<a id=\"32\"></a> <br>\n",
    "##  5-15 AdaBoost classifier\n",
    "\n",
    "An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.\n",
    "This class implements the algorithm known as **AdaBoost-SAMME** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "938946ee8e017b982c4c06e193d4d13cb7d3fb5f"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Model=AdaBoostClassifier()\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "#Accuracy Score\n",
    "print('accuracy is ',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d62842d12731d3eb1d6577c5b35c12c4886c708"
   },
   "source": [
    "<a id=\"33\"></a> <br>\n",
    "## 5-16 Gradient Boosting Classifier\n",
    "GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "863124561c0d1b5995d0b8d3702daa7bc364d6b0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "Model=GradientBoostingClassifier()\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "#Accuracy Score\n",
    "print('accuracy is ',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e89b4494bd78c2d66beeba34a4e320fd8c9dae0c"
   },
   "source": [
    "<a id=\"34\"></a> <br>\n",
    "## 5-17 Linear Discriminant Analysis\n",
    "Linear Discriminant Analysis (discriminant_analysis.LinearDiscriminantAnalysis) and Quadratic Discriminant Analysis (discriminant_analysis.QuadraticDiscriminantAnalysis) are two classic classifiers, with, as their names suggest, a **linear and a quadratic decision surface**, respectively.\n",
    "\n",
    "These classifiers are attractive because they have closed-form solutions that can be easily computed, are inherently multiclass, have proven to work well in practice, and have no **hyperparameters** to tune.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0796cd9f1c902345df605b7557a9c3ff686e35a9"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "Model=LinearDiscriminantAnalysis()\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "#Accuracy Score\n",
    "print('accuracy is ',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "296137970fc94fa4a4eb4185cb5fa952b1985c57"
   },
   "source": [
    "<a id=\"35\"></a> <br>\n",
    "## 5-18 Quadratic Discriminant Analysis\n",
    "A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.\n",
    "\n",
    "The model fits a **Gaussian** density to each class.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5f521d19f295b8e8f24f5715e93b1c45e9a6bce3"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "Model=QuadraticDiscriminantAnalysis()\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "#Accuracy Score\n",
    "print('accuracy is ',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0518634bf8850ac1bfcfc301e93a8740e1995c3a"
   },
   "source": [
    "<a id=\"36\"></a> <br>\n",
    "## 5-19 Kmeans \n",
    "K-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). \n",
    "\n",
    "The goal of this algorithm is **to find groups in the data**, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided.\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f5a41f56ab73cbdc0a3677c27d199fc67407cc59"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Iris(object):\n",
    "    \n",
    "    def data_load(self, datafn=load_iris):\n",
    "        data = datafn()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
    "        return 1\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_load()\n",
    "        return None\n",
    "    \n",
    "    def Kmeans(self, init='random', n_clusters=2, result = 'all'): \n",
    "        km = KMeans(init=init, n_clusters=n_clusters)    \n",
    "        km.fit(self.X_train)\n",
    "        self.X_train = pd.DataFrame(self.X_train)\n",
    "        self.X_test = pd.DataFrame(self.X_test)\n",
    "        if result == 'all':\n",
    "            self.X_train['km'] = km.labels_\n",
    "            self.X_test['km'] = km.predict(self.X_test)\n",
    "        elif result == 'one':\n",
    "            self.X_train = km.labels_.reshape(-1, 1)\n",
    "            self.X_test = km.predict(self.X_test).reshape(-1, 1) \n",
    "        return self\n",
    "    \n",
    "    def model(self, model = LogisticRegression()):\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        predictions = model.predict(self.X_test)\n",
    "        return accuracy_score(self.y_test, predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3c478d3ea88bc5c602c1229347227e69891faaa9"
   },
   "outputs": [],
   "source": [
    "Iris.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "84f37cd1c587667f56cfc33a6ea8364cf2a81da9"
   },
   "outputs": [],
   "source": [
    "Iris().Kmeans(init='random',n_clusters=3,result='all').model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7dfdff6d8a54c846d12a3c234e7765bb7f9d06f3"
   },
   "source": [
    "<a id=\"37\"></a> <br>\n",
    "## 5-20 Plot classification probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f8e04572a7c768f5928229a8896dc65008571cbc"
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, 0:2]  # we only take the first two features for visualization\n",
    "y = iris.target\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "C = 10\n",
    "kernel = 1.0 * RBF([1.0, 1.0])  # for GPC\n",
    "\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'L1 logistic': LogisticRegression(C=C, penalty='l1',\n",
    "                                      solver='saga',\n",
    "                                      multi_class='multinomial',\n",
    "                                      max_iter=10000),\n",
    "    'L2 logistic (Multinomial)': LogisticRegression(C=C, penalty='l2',\n",
    "                                                    solver='saga',\n",
    "                                                    multi_class='multinomial',\n",
    "                                                    max_iter=10000),\n",
    "    'L2 logistic (OvR)': LogisticRegression(C=C, penalty='l2',\n",
    "                                            solver='saga',\n",
    "                                            multi_class='ovr',\n",
    "                                            max_iter=10000),\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,\n",
    "                      random_state=0),\n",
    "    'GPC': GaussianProcessClassifier(kernel)\n",
    "}\n",
    "\n",
    "n_classifiers = len(classifiers)\n",
    "\n",
    "plt.figure(figsize=(3 * 2, n_classifiers * 2))\n",
    "plt.subplots_adjust(bottom=.2, top=.95)\n",
    "\n",
    "xx = np.linspace(3, 9, 100)\n",
    "yy = np.linspace(1, 5, 100).T\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "Xfull = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X, y)\n",
    "\n",
    "    y_pred = classifier.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "\n",
    "    # View probabilities:\n",
    "    probas = classifier.predict_proba(Xfull)\n",
    "    n_classes = np.unique(y_pred).size\n",
    "    for k in range(n_classes):\n",
    "        plt.subplot(n_classifiers, n_classes, index * n_classes + k + 1)\n",
    "        plt.title(\"Class %d\" % k)\n",
    "        if k == 0:\n",
    "            plt.ylabel(name)\n",
    "        imshow_handle = plt.imshow(probas[:, k].reshape((100, 100)),\n",
    "                                   extent=(3, 9, 1, 5), origin='lower')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        idx = (y_pred == k)\n",
    "        if idx.any():\n",
    "            plt.scatter(X[idx, 0], X[idx, 1], marker='o', c='w', edgecolor='k')\n",
    "\n",
    "ax = plt.axes([0.15, 0.04, 0.7, 0.05])\n",
    "plt.title(\"Probability\")\n",
    "plt.colorbar(imshow_handle, cax=ax, orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe3d19ff691fcc7c7edf8d2cb1224e3bdeee396e"
   },
   "source": [
    "<a id=\"47\"></a> <br>\n",
    "# 3- conclusion\n",
    "After the first version of this kernel, in the second edition, we introduced Sklearn. in addition,  we examined each one in detail. this kernel it is not completed yet! Following up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8424e6f84874112757040d36b93542a2e5ba8cb"
   },
   "source": [
    ">###### you may  be interested have a look at it: [**10-steps-to-become-a-data-scientist**](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "you can Fork and Run this kernel on Github:\n",
    "> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    " **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated**\n",
    " \n",
    " -----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1923ba01df86012077df2a2750b92ebb2adb8236"
   },
   "source": [
    "<a id=\"48\"></a> <br>\n",
    "# 4- References\n",
    "1. [Coursera](https://www.coursera.org/specializations/data-science-python)\n",
    "1. [GitHub](https://github.com/mjbahmani)\n",
    "1. [Sklearn](https://scikit-learn.org)\n",
    "1. [Feature Scaling with scikit-learn](http://benalexkeen.com/feature-scaling-with-scikit-learn/)\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f0644ae4e74da4a20cba4e9094ed2458be44361"
   },
   "source": [
    "**you may be interested have a look at it: [Course Home Page](https://www.kaggle.com/mjbahmani/10-steps-to-become-a-data-scientist)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
